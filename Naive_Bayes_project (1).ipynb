{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8d73f12f",
      "metadata": {
        "id": "8d73f12f"
      },
      "source": [
        "**Copyright: © NexStream Technical Education, LLC**.\n",
        "All rights reserved"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5a6719f",
      "metadata": {
        "id": "e5a6719f"
      },
      "source": [
        "# Naive Bayes Multinomial Classifier using Sklearn  \n",
        "\n",
        "In this project, you'll implement a spam email classifier using the Naive Bayes algorithm. This is one of the most common applications of Natural Language Processing (NLP) and provides a simple introduction to text classification.  \n",
        "Spam detection is a binary classification problem: given an email message, we want to classify it as either:\n",
        "- Ham: legitimate, wanted email\n",
        "- Spam: unwanted, unsolicited email\n",
        "\n",
        "The Naive Bayes algorithm is well-suited for text classification because:  \n",
        "- It works well with high-dimensional data (like text)\n",
        "- It can handle small training datasets effectively\n",
        "- It's computationally efficient\n",
        "- It's relatively simple to understand and implement  \n",
        "\n",
        "How Naive Bayes Works for Text:   \n",
        "- Naive Bayes applies Bayes' theorem with a \"naive\" assumption that features (words in our case) are conditionally independent given the class label. For spam classification:\n",
        "  - P(Spam | Message) ∝ P(Spam) × P(Word₁ | Spam) × P(Word₂ | Spam) × ... × P(Wordₙ | Spam)\n",
        "  - For each message, we calculate this probability for both Spam and Ham classes, then classify the message according to which probability is higher.\n",
        "\n",
        "In this project, you will:\n",
        "- Load and explore a dataset of labeled email messages\n",
        "- Prepare the data by splitting it into training and testing sets\n",
        "- Use scikit-learn to vectorize the text data (convert words to features)\n",
        "- Train a Multinomial Naive Bayes classifier\n",
        "- Evaluate the model's performance\n",
        "- Analyze the results and identify the most informative features\n",
        "\n",
        "<br>\n",
        "\n",
        "Follow the instructions in the code cells to complete and test your code. You will replace all triple underscores (___) with your code.\n",
        "Please refer to the lecture slides for details on each of the functions/algorithms and hints on the implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f401e2",
      "metadata": {
        "id": "65f401e2"
      },
      "source": [
        "**Step 1:**  \n",
        "\n",
        "Setup the environment and load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2e9dfac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2e9dfac",
        "outputId": "833c548b-48ac-450d-c32b-1407aa204588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Step 1:\n",
        "\n",
        "#Mount your google drive and copy the dataset to the current working directory (!cp),\n",
        "#or change the working directory to the folder (%cd).\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OpooWpkWg2GP",
      "metadata": {
        "id": "OpooWpkWg2GP"
      },
      "outputs": [],
      "source": [
        "#!ls /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oZnev6qPhQX-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZnev6qPhQX-",
        "outputId": "1dbcaa0e-7c3a-45de-e905-ce038c6a4c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " LinearRegression_project.ipynb         Untitled\n",
            " Naive_Bayes_project.ipynb\t       'Untitled (1)'\n",
            " PCA_LogisticRegression_project.ipynb  'Untitled (2)'\n",
            " spam_training_dataset_2.csv\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Colab\\ Notebooks/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-N2t9Ozphb2l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N2t9Ozphb2l",
        "outputId": "4e1e65dd-baa3-46c9-cf9a-98f04b01b4f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf2306da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf2306da",
        "outputId": "7f702b6c-6b35-4995-f66e-a122515d117d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup the environment and read the dataset\n",
        "\n",
        "# Imports you will need are already provided, no coding needed here.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "\n",
        "# Read the dataset into a Pandas dataframe\n",
        "df = pd.read_csv('spam_training_dataset_2.csv')\n",
        "\n",
        "\n",
        "#For verification purposes - do not change code below this line.\n",
        "import doctest\n",
        "\n",
        "\"\"\"\n",
        "  >>> print(df.shape)\n",
        "  (5563, 2)\n",
        "  >>> print(df['label'].value_counts().iloc[0], df['label'].value_counts().iloc[1])\n",
        "  4818 745\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d690e524",
      "metadata": {
        "id": "d690e524"
      },
      "source": [
        "**Step 2:**  \n",
        "\n",
        "Prepare the dataset\n",
        "- Split the data into train and test sets with 80% train and 20% test\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "950b7611",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "950b7611",
        "outputId": "fde4a218-25ed-4026-cad6-6d9a0fbf018e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 4450 messages\n",
            "Testing set size: 1113 messages\n",
            "\n",
            "Class distribution in training set:\n",
            "label\n",
            "ham     3854\n",
            "spam     596\n",
            "Name: count, dtype: int64\n",
            "Spam ratio: 13.39%\n",
            "\n",
            "Class distribution in testing set:\n",
            "label\n",
            "ham     964\n",
            "spam    149\n",
            "Name: count, dtype: int64\n",
            "Spam ratio: 13.39%\n",
            "\n",
            "Examples from the training set:\n",
            "                                                text label\n",
            "0  Me too baby! I promise to treat you well! I be...   ham\n",
            "1  YOU HAVE WON! As a valued Vodafone customer ou...  spam\n",
            "2                             When did dad get back.   ham\n",
            "3  Daddy, shu shu is looking 4 u... U wan me 2 te...   ham\n",
            "4                             Remember on that day..   ham\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=4)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "# Set the random_state = 42 for reproducibility\n",
        "# Set stratify=df['label'] to ensure the same ham/spam ratio\n",
        "X_train, X_test, y_train, y_test =  train_test_split(   # train test split function\n",
        "                                    df['text'],          # email text content\n",
        "                                    df['label'],          # labels (ham/spam)\n",
        "                                    test_size=0.2,        # Use 80% train, 20% test split\n",
        "                                    random_state = 42,      # Set a random seed = 42 for reproducibility\n",
        "                                    stratify=df['label'] # Set stratify to ensure the same ham/spam ratio in both sets\n",
        ")\n",
        "\n",
        "# Display the shapes of our training and testing sets\n",
        "print(f\"Training set size: {X_train.shape[0]} messages\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} messages\")\n",
        "\n",
        "# Check class distribution in training and testing sets\n",
        "print(\"\\nClass distribution in training set:\")\n",
        "print(y_train.value_counts())\n",
        "print(f\"Spam ratio: {y_train.value_counts(normalize=True)['spam']:.2%}\")\n",
        "\n",
        "print(\"\\nClass distribution in testing set:\")\n",
        "print(y_test.value_counts())\n",
        "print(f\"Spam ratio: {y_test.value_counts(normalize=True)['spam']:.2%}\")\n",
        "\n",
        "# Display a few examples from the training set\n",
        "print(\"\\nExamples from the training set:\")\n",
        "train_examples = pd.DataFrame({\n",
        "    'text': X_train.iloc[:5].values,\n",
        "    'label': y_train.iloc[:5].values\n",
        "})\n",
        "print(train_examples)\n",
        "\n",
        "\n",
        "#For verification purposes - do not change code below this line.\n",
        "import doctest\n",
        "\n",
        "\"\"\"\n",
        "  >>> print(X_train.shape[0])\n",
        "  4450\n",
        "  >>> print(X_test.shape[0])\n",
        "  1113\n",
        "  >>> np.isclose(y_train.value_counts(normalize=True)['spam'], 0.13393258426966292, atol=10e-3)\n",
        "  np.True_\n",
        "  >>> np.isclose(y_test.value_counts(normalize=True)['ham'], 0.8660674157303371, atol=10e-3)\n",
        "  np.True_\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e08de4",
      "metadata": {
        "id": "b3e08de4"
      },
      "source": [
        "**Step 3:**  \n",
        "\n",
        "Create a Pipeline containing the sequence of processing functions to train a Multinomial Naive Bayes model.  \n",
        "\n",
        "<br>\n",
        "\n",
        "Pipeline:   \n",
        "Chains together multiple data processing steps. It's useful for tasks that involve preprocessing, feature engineering, and model training.  \n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html   \n",
        "- Processing blocks are identified with a list of steps accessed by name, e.g. 'scalar', 'classifier', 'vectorizer'.  \n",
        "- e.g. *pipeline = Pipeline([ ('scaler', StandardScaler()), ('classifier', LogisticRegression()) ])*\n",
        "\n",
        "  Our Pipeline for text classification will consist of:\n",
        "  - A text transformer (CountVectorizer).  \n",
        "    - Specify this with 'vectorizer'.\n",
        "    - Set the minimum document frequency (*min_df*) for a word to be included to 2\n",
        "    - Use only single words (unigrams).  This done by setting *ngram_range* to (1,1)\n",
        "  - A classifier (MultinomialNB).  Specify this with 'classifier'\n",
        "\n",
        "<br>\n",
        "\n",
        "CountVectorizer:   \n",
        "Converts the dataset text to features.  Use CountVectorizer in your implementation which will perform the following operations:\n",
        "  - Tokenize: The text is split into individual words (tokens)\n",
        "  - Build Vocabulary: A vocabulary of unique words is created from all documents\n",
        "  - Create Vector: Each document is converted into a vector where:  \n",
        "    - Each position corresponds to a word in the vocabulary\n",
        "    - The value is the count of that word in the document\n",
        "\n",
        "See the LSA lecture and sklearn library API for more details and examples on CountVectorizer.\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "\n",
        "<br>\n",
        "\n",
        "MultiNomialNB:   \n",
        "Classification algorithm that can be used on datasets with discrete features, commonly used in text classification where features represent word counts.\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
        "- Parameter alpha adds value (e.g. 1.0) to the feature counts to prevent zero frequency problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f282c7c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f282c7c7",
        "outputId": "a0d7c07e-c75a-4fcb-9ea6-bea72e17b0e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=1)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 3:\n",
        "\n",
        "# Create a pipeline with CountVectorizer and MultinomialNB\n",
        "# CountVectorizer converts text to word count features\n",
        "# MultinomialNB is the Multinomial Naive Bayes classifier\n",
        "\n",
        "pipeline = Pipeline([      #Initialize Pipeline reference\n",
        "           ('vectorizer', CountVectorizer(    # set vectorizer\n",
        "               stop_words = 'english',  #  remove English stop words\n",
        "               min_df = 2,    #  set minimum doc frequency for a term to be included to 2\n",
        "               ngram_range=(1,1), #  use unigrams (single words)\n",
        "              )\n",
        "           ),\n",
        "\n",
        "          ('classifier', MultinomialNB(            # set classifier\n",
        "              alpha=1.0)    #    set alpha to 1.0 to prevent zero frequency problems\n",
        "          )\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "#For verification purposes - do not change code below this line.\n",
        "import doctest\n",
        "\n",
        "\"\"\"\n",
        "  >>> print(pipeline.steps)\n",
        "  [('vectorizer', CountVectorizer(min_df=2, stop_words='english')), ('classifier', MultinomialNB())]\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ccd54e",
      "metadata": {
        "id": "40ccd54e"
      },
      "source": [
        "**Step 4:**   \n",
        "\n",
        "Train the model, make predictions, and calculate accuracy\n",
        "- Use the Pipeline *fit* function.\n",
        "- Use the Pipeline *predict* function.\n",
        "- Use sklearn.metrics *accuracy_score* function.\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
        "\n",
        "Print out a classification report for the model\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a260713",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a260713",
        "outputId": "f6b8b284-61ac-4e91-83a2-f4d078844349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.9847\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.99      0.99       964\n",
            "        spam       0.96      0.93      0.94       149\n",
            "\n",
            "    accuracy                           0.98      1113\n",
            "   macro avg       0.97      0.96      0.97      1113\n",
            "weighted avg       0.98      0.98      0.98      1113\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[958   6]\n",
            " [ 11 138]]\n",
            "\n",
            "Spam Detection Metrics:\n",
            "Spam Precision: 0.9583 (higher is better)\n",
            "Spam Recall: 0.9262 (higher is better)\n",
            "False Positive Rate: 0.0062 (lower is better)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=4)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 4:\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Print some metrics that are typical for spam filters\n",
        "# Calculations provided - no coding needed here.\n",
        "\n",
        "print(\"\\nSpam Detection Metrics:\")\n",
        "# Calculate precision for 'spam' class (how many predicted spam are actually spam)\n",
        "spam_precision = conf_matrix[1, 1] / (conf_matrix[0, 1] + conf_matrix[1, 1])\n",
        "# Calculate recall for 'spam' class (how many actual spam were caught)\n",
        "spam_recall = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
        "# Calculate false positive rate (ham incorrectly classified as spam)\n",
        "false_positive_rate = conf_matrix[0, 1] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
        "\n",
        "print(f\"Spam Precision: {spam_precision:.4f} (higher is better)\")\n",
        "print(f\"Spam Recall: {spam_recall:.4f} (higher is better)\")\n",
        "print(f\"False Positive Rate: {false_positive_rate:.4f} (lower is better)\")\n",
        "\n",
        "\n",
        "\n",
        "#For verification purposes - do not change code below this line.\n",
        "import doctest\n",
        "\n",
        "\"\"\"\n",
        "  >>> np.isclose(accuracy, 0.98472597, atol=10e-3)\n",
        "  np.True_\n",
        "  >>> np.isclose(spam_precision, 0.95833333, atol=10e-3)\n",
        "  np.True_\n",
        "  >>> np.isclose(spam_recall, 0.92617450, atol=10e-3)\n",
        "  np.True_\n",
        "  >>> np.isclose(false_positive_rate, 0.00622407, atol=10e-3)\n",
        "  np.True_\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a703e962",
      "metadata": {
        "id": "a703e962"
      },
      "source": [
        "#Reflection Questions  \n",
        "\n",
        "Using your notebook results, answer the following questions:  \n",
        "\n",
        "1. The Naive Bayes algorithm makes a fundamental \"naive\" assumption that is known to be incorrect in real-world text data, yet the algorithm still performs well for our spam filter application.\n",
        "  - What is this \"naive\" assumption?\n",
        "  - Provide an example from email text that contradicts this assumption.\n",
        "  - Why does Naive Bayes still perform well for spam detection despite this incorrect assumption?\n",
        "  - How might this assumption affect performance differently in other NLP tasks compared to spam detection?\n",
        "\n",
        "2. Run the \"Examine most informative features\" code section below to identify the most informative words for spam and ham classification.\n",
        "  - List the top 5 words most strongly associated with spam and explain why these words make intuitive sense for spam detection.\n",
        "  - List 2-3 words that are strongly associated with ham (legitimate emails) and explain their significance.\n",
        "  - Identify at least one word in the top results that surprised you, and explain why.\n",
        "  - If you were to improve the spam filter, would you manually add or remove any specific features (words) based on this analysis? Why or why not?\n",
        "\n",
        "3. When implementing a Naive Bayes spam filter in a real-world email system, various trade-offs must be considered.\n",
        "  - Explain the trade-off between precision and recall in the context of spam filtering. Which metric would you prioritize and why?\n",
        "  - How would you adjust the model to minimize the risk of important legitimate emails being classified as spam? Be specific about which parameters you would modify.\n",
        "  - Our model used only unigrams (single words) as features. Discuss one advantage and one disadvantage of extending the model to include bigrams (word pairs) for spam detection.\n",
        "  - Multinomial Naive Bayes uses Laplace (add-one) smoothing to handle unseen words. Explain why this smoothing is necessary and how it would affect classification of an email containing words not seen during training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28611d9",
      "metadata": {},
      "source": [
        "Reflection:\n",
        "\n",
        "Using your notebook results, answer the following questions:\n",
        "\n",
        "1. The Naive Bayes algorithm makes a fundamental \"naive\" assumption that is known to be incorrect in real-world text data, yet the algorithm still performs well for our spam filter application.\n",
        "   - What is this \"naive\" assumption?\n",
        "   - Provide an example from email text that contradicts this assumption.\n",
        "   - Why does Naive Bayes still perform well for spam detection despite this incorrect assumption?\n",
        "   - How might this assumption affect performance differently in other NLP tasks compared to spam detection?\n",
        "\n",
        "**My Ans:** The naive assumption is the conditional independence between each features given the class label (y). A contradiction example might be: P(hotel|Spam) might not be independent from P(trip|Spam). Naive Bayes still performs well probably because the correlated spam words wouldn't hinder the classification of Spam/non-spam email, as they would increase the probability of the Spam email being classified as Spam. When the sequence of the sentence matters, but not simple classification, the performance would be affected by wrong models.\n",
        "\n",
        "\n",
        "\n",
        "2. Run the \"Examine most informative features\" code section below to identify the most informative words for spam and ham classification.\n",
        "\n",
        "- List the top 5 words most strongly associated with spam and explain why these words make intuitive sense for spam detection.\n",
        "- List 2-3 words that are strongly associated with ham (legitimate emails) and explain their significance.\n",
        "- Identify at least one word in the top results that surprised you, and explain why.\n",
        "- If you were to improve the spam filter, would you manually add or remove any specific features (words) based on this analysis? Why or why not?\n",
        "\n",
        "**My Ans:** According to the result, the top 5 words associated with spam are \"claim\", \"prize\", \"150p\", \"tone\", and \"18\". These words connect with the contents, such as \"claim your prize\", \"18+\", which are quite spammy. The top 3 words with legitimate emails can be: \"later\",  \"said\",  \"ask\".  These words are often used in our daily life or work. The words \"gt\", \"lt\" actually surprised me because these are not human-used words, but HTML-entity artifacts. These HTML artifacts can both appear in spam or legitimate emails. Therefore, to improve the spam filter, we can manually remove these non-human language words so that we can reduce noise.\n",
        "\n",
        "\n",
        "\n",
        "3. When implementing a Naive Bayes spam filter in a real-world email system, various trade-offs must be considered.\n",
        "\n",
        "- Explain the trade-off between precision and recall in the context of spam filtering. Which metric would you prioritize and why?\n",
        "- How would you adjust the model to minimize the risk of important legitimate emails being classified as spam? Be specific about which parameters you would modify.\n",
        "- Our model used only unigrams (single words) as features. Discuss one advantage and one disadvantage of extending the model to include bigrams (word pairs) for spam detection.\n",
        "- Multinomial Naive Bayes uses Laplace (add-one) smoothing to handle unseen words. Explain why this smoothing is necessary and how it would affect classification of an email containing words not seen during training.\n",
        "\n",
        "**My Ans:** \n",
        "\n",
        "Precision measures: among all emails that we mark as spam, how many of them are true spam emails; while recall measures: among all true spam emails, how many do we mark as spam. They are related to the two types of errors. I think in real-world scenario, the precision would be more useful, because people care more about whether their legitimate emails are mistakenly marked as spam. To minimize the risk of important legitimate emails being classified as spam, we can enhance the decision threshold or adjust the prior P(spam). \n",
        "\n",
        "One advantage of including the bigram is that, it takes phrases into account; however, including both unigram and bigram would increase the data and decrease the efficiency, and that would be a disadvantage of it. \n",
        "\n",
        "Smoothing is important to avoid including \"zero possibility\" when encountering unseen words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e32c208e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e32c208e",
        "outputId": "bc2f738e-2d6c-4ada-d6fc-e1ec59a22153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top Spam-indicating words:\n",
            "claim: 5.3464\n",
            "prize: 4.9786\n",
            "150p: 4.8245\n",
            "tone: 4.5491\n",
            "18: 4.4991\n",
            "cs: 4.4731\n",
            "500: 4.4731\n",
            "guaranteed: 4.4190\n",
            "100: 4.3320\n",
            "uk: 4.3013\n",
            "1000: 4.2695\n",
            "landline: 4.2028\n",
            "awarded: 4.2028\n",
            "www: 4.1314\n",
            "ringtone: 4.1314\n",
            "150ppm: 4.1314\n",
            "collection: 4.0136\n",
            "5000: 3.9266\n",
            "16: 3.9266\n",
            "000: 3.9266\n",
            "\n",
            "Top Ham-indicating words:\n",
            "gt: -4.7366\n",
            "lt: -4.7290\n",
            "lor: -4.0698\n",
            "da: -4.0473\n",
            "later: -3.8466\n",
            "wat: -3.6531\n",
            "amp: -3.5212\n",
            "ask: -3.4820\n",
            "said: -3.4130\n",
            "home: -3.3840\n",
            "cos: -3.3541\n",
            "doing: -3.3541\n",
            "come: -3.2916\n",
            "morning: -3.2588\n",
            "really: -3.2588\n",
            "lol: -3.2075\n",
            "sure: -3.1898\n",
            "ll: -3.1673\n",
            "gud: -3.1535\n",
            "nice: -3.1348\n",
            "\n",
            "Baseline (majority class) accuracy: 0.8661\n",
            "Our model improvement over baseline: 0.1186\n"
          ]
        }
      ],
      "source": [
        "# Examine most informative features\n",
        "# Run this cell and use the output to answer the Reflection question above.\n",
        "\n",
        "def show_most_informative_features(vectorizer, classifier, n=20):\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    # Get the log probability ratios for features\n",
        "    coefs_with_fns = sorted(zip(classifier.feature_log_prob_[1] - classifier.feature_log_prob_[0],\n",
        "                               feature_names))\n",
        "    # Get top features for spam (positive coefficient)\n",
        "    top_spam = coefs_with_fns[-n:]\n",
        "    # Get top features for ham (negative coefficient)\n",
        "    top_ham = coefs_with_fns[:n]\n",
        "\n",
        "    print(\"\\nTop Spam-indicating words:\")\n",
        "    for coef, feat in reversed(top_spam):\n",
        "        print(f\"{feat}: {coef:.4f}\")\n",
        "\n",
        "    print(\"\\nTop Ham-indicating words:\")\n",
        "    for coef, feat in top_ham:\n",
        "        print(f\"{feat}: {coef:.4f}\")\n",
        "\n",
        "# Get the vectorizer and classifier from the pipeline\n",
        "vectorizer = pipeline.named_steps['vectorizer']\n",
        "classifier = pipeline.named_steps['classifier']\n",
        "\n",
        "# Show most informative features\n",
        "show_most_informative_features(vectorizer, classifier)\n",
        "\n",
        "# Compare with baseline (always predict majority class)\n",
        "majority_class = y_train.mode()[0]\n",
        "baseline_accuracy = (y_test == majority_class).mean()\n",
        "print(f\"\\nBaseline (majority class) accuracy: {baseline_accuracy:.4f}\")\n",
        "print(f\"Our model improvement over baseline: {accuracy - baseline_accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
